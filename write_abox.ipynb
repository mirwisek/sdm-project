{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Literal, Namespace, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD, DC\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Specify the directory path\n",
    "directory = \"ABOX\"\n",
    "\n",
    "file_attrs = {}\n",
    "\n",
    "# Create the RDF graph\n",
    "tbox = Graph()\n",
    "\n",
    "abox = Graph()\n",
    "# Define the namespaces\n",
    "ns = Namespace(\"http://www.fraudanalytix.com/schema/\")\n",
    "l = Namespace(\"http://www.fraudanalytix.com/schema/l/\")\n",
    "f = Namespace(\"http://www.fraudanalytix.com/schema/f/\")\n",
    "e = Namespace(\"http://www.fraudanalytix.com/schema/e/\")\n",
    "\n",
    "# Parse the TBOX from FA.ttl file\n",
    "tbox.parse(\"FA-tbox.ttl\", format=\"ttl\")\n",
    "\n",
    "abox.bind('fa', ns)\n",
    "abox.bind('l', l)\n",
    "abox.bind('f', f)\n",
    "abox.bind('e', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_headers(file_dict, data_file):\n",
    "    # Read transactions.csv and add ABOX triples to the graph\n",
    "    with open(data_file, \"r\") as file:\n",
    "        attribute_names = set()\n",
    "        if '.json' in data_file:\n",
    "            # Read the JSON file\n",
    "            data = json.load(file)\n",
    "            for item in data:\n",
    "                # Get the keys of each item\n",
    "                keys = item.keys()\n",
    "                # Add the keys to the set of attribute names\n",
    "                attribute_names.update(keys)\n",
    "        else:\n",
    "            # Read the column headers\n",
    "            attribute_names.update(file.readline().strip().split(\",\"))\n",
    "            \n",
    "        dir = data_file.replace(directory + '\\\\', '')\n",
    "        file_dict[dir] = attribute_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clientA\\cardprograms_2023-05-28_11-30-01.csv\n",
      "{'currency', 'withdraw_limit', 'bank', 'card_no', 'last_updated', 'expiration_months', 'card_program', 'min_load_amount', 'start_date', 'program_id', 'pin_length', 'max_load_amount', 'max_transfer_amount', 'is_virtual_available', 'min_transfer_amount'}\n",
      "clientA\\cardprograms_2023-05-31_10-57-05.csv\n",
      "{'currency', 'withdraw_limit', 'bank', 'card_no', 'last_updated', 'expiration_months', 'card_program', 'min_load_amount', 'start_date', 'program_id', 'pin_length', 'max_load_amount', 'max_transfer_amount', 'is_virtual_available', 'min_transfer_amount'}\n",
      "clientA\\cards_2023-05-28_11-30-01.csv\n",
      "{'ccv_status', 'work_phone_no', 'birth_country_code', 'pos_ol_withd_limit', 'tot_trans_amount', 'zip_postal_code', 'nlast_declines', 'last_act_on', 'name_on_card', 'gender', 'card_status_atm', 'address2', 'atm_of_withd_limit', 'card_status', 'state_code', 'card_status_pos', 'mobile_no', 'status_map_no', 'atm_ol_withd_limit', 'home_phone_no', 'is_main_card', 'avs_status', 'err_code', 'card_members', 'email', 'first_inact_on', 'cr_ol_withd_limit', 'tot_coms_amount', 'created_on', 'ofac_status', 'card_no', 'last_trans_dtime', 'city', 'customer_id', 'first_act_on', 'address1', 'nlost_stolens', 'cr_of_withd_limit', 'last_inact_on'}\n",
      "clientA\\cards_2023-05-31_10-57-05.csv\n",
      "{'ccv_status', 'work_phone_no', 'birth_country_code', 'pos_ol_withd_limit', 'tot_trans_amount', 'zip_postal_code', 'nlast_declines', 'last_act_on', 'name_on_card', 'gender', 'card_status_atm', 'address2', 'atm_of_withd_limit', 'card_status', 'state_code', 'card_status_pos', 'mobile_no', 'status_map_no', 'atm_ol_withd_limit', 'home_phone_no', 'is_main_card', 'avs_status', 'err_code', 'card_members', 'email', 'first_inact_on', 'cr_ol_withd_limit', 'tot_coms_amount', 'created_on', 'ofac_status', 'card_no', 'last_trans_dtime', 'city', 'customer_id', 'first_act_on', 'address1', 'nlost_stolens', 'cr_of_withd_limit', 'last_inact_on'}\n",
      "clientA\\customers_2023-05-28_11-30-01.csv\n",
      "{'date_of_birth', 'last_name', 'country_of_birth', 'bill_country_code', 'driving_license_no', 'gender', 'country_code', 'occupation', 'address', 'zip_code', 'national_id', 'mobile_no', 'bill_zip_code', 'email', 'marital_status', 'city', 'customer_id', 'bill_address', 'bill_city', 'first_name', 'ssn'}\n",
      "clientA\\customers_2023-05-31_10-57-05.csv\n",
      "{'date_of_birth', 'last_name', 'country_of_birth', 'bill_country_code', 'driving_license_no', 'gender', 'country_code', 'occupation', 'address', 'zip_code', 'national_id', 'mobile_no', 'bill_zip_code', 'email', 'marital_status', 'city', 'customer_id', 'bill_address', 'bill_city', 'first_name', 'ssn'}\n",
      "clientA\\geodata_2023-05-28_11-30-01.json\n",
      "{'boundingbox', 'lon', 'osm_type', 'name', 'category', 'type', 'osm_id', 'place_id', 'lat', 'place_rank', 'display_name', 'importance', 'address', 'licence', 'addresstype'}\n",
      "clientA\\geodata_2023-05-31_10-57-05.json\n",
      "{'boundingbox', 'lon', 'osm_type', 'name', 'category', 'type', 'osm_id', 'place_id', 'lat', 'place_rank', 'display_name', 'importance', 'address', 'licence', 'addresstype'}\n",
      "clientA\\transactions_2023-05-28_11-30-01.csv\n",
      "{'currency', 'coordinates', 'iso_message_type', 'merchant_cat_code', 'card_no', 'service_id', 'customer_id', 'device_type', 'transaction_id', 'is_international', 'response_code', 'amount_processed', 'amount_requested', 'point_of_srv_code', 'fparam_code', 'trans_dtime'}\n",
      "clientA\\transactions_2023-05-31_10-57-05.csv\n",
      "{'currency', 'coordinates', 'iso_message_type', 'merchant_cat_code', 'card_no', 'service_id', 'customer_id', 'device_type', 'transaction_id', 'is_international', 'response_code', 'amount_processed', 'amount_requested', 'point_of_srv_code', 'fparam_code', 'trans_dtime'}\n",
      "mcc_2023-05-28_11-30-01.csv\n",
      "{'merchant_cat_code', 'edited_description', 'combined_description', 'irs_reportable', 'irs_description', 'usda_description'}\n",
      "mcc_2023-05-31_10-57-05.csv\n",
      "{'merchant_cat_code', 'edited_description', 'combined_description', 'irs_reportable', 'irs_description', 'usda_description'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to recursively loop through files in a directory\n",
    "def process_files(directory, parent = ''):\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if os.path.isdir(file_path):\n",
    "            # Recursively call the function for subdirectories\n",
    "            process_files(file_path)\n",
    "        else:\n",
    "            # Process the file\n",
    "            read_headers(file_attrs, file_path)\n",
    "\n",
    "# Call the function to process files in the directory and its subdirectories\n",
    "process_files(directory)\n",
    "\n",
    "for i,k in file_attrs.items():\n",
    "    print(i)\n",
    "    print(k)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a provider only once, to ensure we don't create more than once (RDFLib can manage it but still for perfomance reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N8671d00729174e2da21dfb0a95d7a72b (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = l.DataSource1\n",
    "abox.add((root, RDF.type, l.DataSources))\n",
    "abox.add((root, RDFS.label, Literal('DataSource1', lang=\"en\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createProviderFile(provider):\n",
    "    uri = l[provider]\n",
    "    if provider not in clients:\n",
    "        clients.add(provider)\n",
    "\n",
    "        abox.add((uri, RDF.type, l.DataProvider))\n",
    "        abox.add((uri, RDFS.label, Literal(provider, lang=\"en\")))\n",
    "        abox.add((root, l.hasDataProvider, uri))\n",
    "    return uri"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['clientA\\\\cardprograms', 'clientA\\\\cards', 'clientA\\\\customers', 'clientA\\\\geodata', 'clientA\\\\transactions', 'mcc'])\n"
     ]
    }
   ],
   "source": [
    "landing_files = dict()\n",
    "for file, attrs in file_attrs.items():\n",
    "    filename = file\n",
    "    fkey = None\n",
    "    if '\\\\' in file:\n",
    "        dir, filename = file.split('\\\\')\n",
    "        fkey = dir + '\\\\' + filename.split('_')[0]\n",
    "    else:\n",
    "        fkey = filename.split('_')[0]\n",
    "    landing_files[fkey] = attrs\n",
    "\n",
    "print(landing_files.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardprograms clientA\n",
      "cards clientA\n",
      "customers clientA\n",
      "geodata clientA\n",
      "transactions clientA\n",
      "mcc\n"
     ]
    }
   ],
   "source": [
    "for file, attrs in landing_files.items():\n",
    "\n",
    "    if '\\\\' in file:\n",
    "        dir, filename = file.split('\\\\')\n",
    "        print(filename, dir)\n",
    "\n",
    "        provider = createProviderFile(dir)\n",
    "\n",
    "        object = l[filename]\n",
    "        abox.add((object, RDF.type, l.DataFile))\n",
    "        abox.add((object, RDFS.label, Literal(filename, lang=\"en\")))\n",
    "        abox.add((provider, l.providesDataFile, object))\n",
    "\n",
    "    # Iterate over the column headers and create triples\n",
    "    else:\n",
    "        print(file)\n",
    "        object = l[file]\n",
    "        abox.add((object, RDF.type, l.DataFile))\n",
    "        abox.add((object, RDFS.label, Literal(file, lang=\"en\")))\n",
    "        abox.add((root, l.hasDataFile, object))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatted Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardprograms_2023-05-28_11-30-01.csv clientA\n",
      "cardprograms_2023-05-31_10-57-05.csv clientA\n",
      "cards_2023-05-28_11-30-01.csv clientA\n",
      "cards_2023-05-31_10-57-05.csv clientA\n",
      "customers_2023-05-28_11-30-01.csv clientA\n",
      "customers_2023-05-31_10-57-05.csv clientA\n",
      "geodata_2023-05-28_11-30-01.json clientA\n",
      "geodata_2023-05-31_10-57-05.json clientA\n",
      "transactions_2023-05-28_11-30-01.csv clientA\n",
      "transactions_2023-05-31_10-57-05.csv clientA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nd7dc0749af0647e9bc0c03eeca46769e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file, attrs in file_attrs.items():\n",
    "\n",
    "    if '\\\\' in file:\n",
    "        dir, filename = file.split('\\\\')\n",
    "        print(filename, dir)\n",
    "\n",
    "        provider = createProviderFile(dir)\n",
    "\n",
    "        object = l[dir + '_' + filename]\n",
    "        abox.add((object, RDF.type, ns.DataFile))\n",
    "        abox.add((object, RDFS.label, Literal(dir, lang=\"en\")))\n",
    "        abox.add((provider, l.providesDataFile, object))\n",
    "\n",
    "        # for attr in attrs:\n",
    "        #     attribute_uri = URIRef(l + dir + filename)\n",
    "        #     abox.add((attribute_uri, RDF.type, ns.Attribute))\n",
    "        #     abox.add((attribute_uri, RDFS.label, Literal(dir, lang=\"en\")))\n",
    "        #     abox.add((ns.DataFile, ns.hasAttribute, attribute_uri))\n",
    "\n",
    "    # Iterate over the column headers and create triples\n",
    "    # else:\n",
    "    #     print(file)\n",
    "    #     attribute_uri = URIRef(l + file)\n",
    "    #     abox.add((attribute_uri, RDF.type, ns.Attribute))\n",
    "    #     abox.add((attribute_uri, RDFS.label, Literal(file, lang=\"en\")))\n",
    "    #     abox.add((ns.DataFile, ns.hasAttribute, attribute_uri))\n",
    "\n",
    "# Serialize the updated graph to FA_updated.ttl file\n",
    "abox.serialize(\"FA_ABOX.nt\", format=\"ttl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nc60274697aff40828ac2db1e760d65c2 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abox.serialize(\"FA_ABOX.nt\", format=\"ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add((ns.Attribute, RDF.type, OWL.Class))\n",
    "graph.add((ns.Attribute, RDFS.label, Literal(\"Attribute\", lang=\"en\")))\n",
    "\n",
    "graph.add((ns.File, RDF.type, OWL.Class))\n",
    "graph.add((ns.File, RDFS.label, Literal(\"File\", lang=\"en\")))\n",
    "\n",
    "graph.add((e.PreprocessedFile, RDF.type, OWL.Class))\n",
    "graph.add((e.PreprocessedFile, RDFS.label, Literal(\"PreprocessedFile\", lang=\"en\")))\n",
    "graph.add((e.PreprocessedFile, RDFS.subClassOf, ns.File))\n",
    "\n",
    "graph.add((e.fileGeneratedFrom, RDF.type, OWL.ObjectProperty))\n",
    "graph.add((e.fileGeneratedFrom, RDFS.domain, e.PreprocessedFile))\n",
    "graph.add((e.fileGeneratedFrom, RDFS.label, Literal(\"fileGeneratedFrom\", lang=\"en\")))\n",
    "graph.add((e.fileGeneratedFrom, RDFS.range, f.FormattedFile))\n",
    "\n",
    "graph.add((f.FormattedFile, RDF.type, OWL.Class))\n",
    "graph.add((f.FormattedFile, RDFS.label, Literal(\"FormattedFile\", lang=\"en\")))\n",
    "graph.add((f.FormattedFile, RDFS.subClassOf, ns.File))\n",
    "\n",
    "graph.add((ns.hasAttribute, RDF.type, OWL.ObjectProperty))\n",
    "graph.add((ns.hasAttribute, RDFS.domain, ns.File))\n",
    "graph.add((ns.hasAttribute, RDFS.label, Literal(\"hasAttribute\", lang=\"en\")))\n",
    "graph.add((ns.hasAttribute, RDFS.range, ns.Attribute))\n",
    "\n",
    "graph.add((l.DataFile, RDF.type, OWL.Class))\n",
    "graph.add((l.DataFile, RDFS.label, Literal(\"DataFile\", lang=\"en\")))\n",
    "graph.add((l.DataFile, RDFS.subClassOf, ns.File))\n",
    "\n",
    "graph.add((l.DataProvider, RDF.type, OWL.Class))\n",
    "graph.add((l.DataProvider, RDFS.label, Literal(\"DataProvider\", lang=\"en\")))\n",
    "\n",
    "graph.add((l.DataSource, RDF.type, OWL.Class))\n",
    "graph.add((l.DataSource, RDFS.label, Literal(\"DataSource\", lang=\"en\")))\n",
    "\n",
    "graph.add((l.FileVersion, RDF.type, OWL.Class))\n",
    "graph.add((l.FileVersion, RDFS.label, Literal(\"FileVersion\", lang=\"en\")))\n",
    "graph.add((l.FileVersion, RDFS.subClassOf, f.FormattedFile))\n",
    "\n",
    "graph.add((l.hasDataFile, RDF.type, OWL.ObjectProperty))\n",
    "graph.add((l.hasDataFile, RDFS.domain, l.DataSource))\n",
    "graph.add((l.hasDataFile, RDFS.label, Literal(\"hasDataFile\", lang=\"en\")))\n",
    "graph.add((l.hasDataFile, RDFS.range, l.DataFile))\n",
    "graph.add((l.hasDataFile, RDFS.subPropertyOf, l.providesDataFile))\n",
    "\n",
    "graph.add((l.hasDataProvider, RDF.type, OWL.ObjectProperty))\n",
    "graph.add((l.hasDataProvider, RDFS.domain, l.DataSource))\n",
    "graph.add((l.hasDataProvider, RDFS.label, Literal(\"hasDataProvider\", lang=\"en\")))\n",
    "graph.add((l.hasDataProvider, RDFS.range, l.DataProvider))\n",
    "graph.add((l.hasDataProvider, RDFS.subPropertyOf, l.providesDataFile))\n",
    "\n",
    "graph.add((l.hasFileVersion, RDF.type, OWL.ObjectProperty))\n",
    "graph.add((l.hasFileVersion, RDFS.domain, l.DataFile))\n",
    "graph.add((l.hasFileVersion, RDFS.label, Literal(\"hasFileVersion\", lang=\"en\")))\n",
    "graph.add((l.hasFileVersion, RDFS.range, l.FileVersion))\n",
    "\n",
    "graph.add((l.providesDataFile, RDF.type, OWL.ObjectProperty))\n",
    "graph.add((l.providesDataFile, RDFS.domain, l.DataProvider))\n",
    "graph.add((l.providesDataFile, RDFS.label, Literal(\"providesDataFile\", lang=\"en\")))\n",
    "graph.add((l.providesDataFile, RDFS.range, l.DataFile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
